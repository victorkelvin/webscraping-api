# ğŸ•·ï¸ Web Scraping API

Uma API REST robusta e flexÃ­vel para web scraping, construÃ­da com Flask e BeautifulSoup. Perfeita para extrair dados de pÃ¡ginas web de forma programÃ¡tica e escalÃ¡vel.

## âœ¨ CaracterÃ­sticas

- ğŸš€ **API RESTful** - Endpoints bem estruturados e documentados
- ğŸ›¡ï¸ **Tratamento de Erros** - ValidaÃ§Ã£o de entrada e tratamento robusto de exceÃ§Ãµes
- ğŸŒ **CORS Habilitado** - Pronto para uso em aplicaÃ§Ãµes web frontend
- ğŸ“¦ **Containerizado** - Docker pronto para deployment
- ğŸ” **Scraping Inteligente** - ExtraÃ§Ã£o automÃ¡tica de produtos de e-commerce
- ğŸ“ **Logging Completo** - Monitoramento e debugging facilitados
- âš¡ **Performance** - Headers otimizados e sessÃµes reutilizÃ¡veis

## ğŸ› ï¸ Tecnologias

- **Flask** - Framework web minimalista e flexÃ­vel
- **BeautifulSoup4** - Parser HTML/XML poderoso
- **Requests** - Cliente HTTP elegante
- **Docker** - ContainerizaÃ§Ã£o para deployment
- **Gunicorn** - Servidor WSGI para produÃ§Ã£o

## ğŸ“‹ PrÃ©-requisitos

- Python 3.8+
- pip
- Docker (opcional)

## ğŸš€ InstalaÃ§Ã£o

### InstalaÃ§Ã£o Local

```bash
# Clone o repositÃ³rio
git clone https://github.com/victorkelvin/webscraping-api.git
cd webscraping-api

# Instale as dependÃªncias
pip install -r requirements.txt

# Execute a aplicaÃ§Ã£o
python app.py
```

### Usando Docker

```bash
# Build da imagem
docker build -t webscraping-api .

# Execute o container
docker run -p 5000:5000 webscraping-api
```

## ğŸ“– DocumentaÃ§Ã£o da API

### Base URL
```
http://localhost:5000
```

### Endpoints

#### ğŸ  GET `/`
InformaÃ§Ãµes gerais da API
```json
{
  "message": "Web Scraping API",
  "version": "1.0.0",
  "endpoints": {
    "/scrape": "POST - Faz scraping bÃ¡sico de uma URL",
    "/scrape/products": "POST - Extrai produtos de uma pÃ¡gina de e-commerce",
    "/health": "GET - Status da API"
  }
}
```

#### ğŸ’“ GET `/health`
Health check da API
```json
{
  "status": "healthy",
  "timestamp": "2024-01-15T10:30:00.000Z",
  "service": "Web Scraping API"
}
```

#### ğŸ” POST `/scrape`
Extrai informaÃ§Ãµes bÃ¡sicas de uma pÃ¡gina web

**Request:**
```json
{
  "url": "https://example.com"
}
```

**Response:**
```json
{
  "url": "https://example.com",
  "title": "Example Domain",
  "description": "This domain is for use in illustrative examples",
  "images": [
    {
      "url": "https://example.com/image.jpg",
      "alt": "Example image",
      "title": "Example"
    }
  ],
  "links": [
    {
      "url": "https://example.com/link",
      "text": "More information...",
      "title": "Link title"
    }
  ],
  "headings": [
    {
      "level": 1,
      "text": "Example Domain"
    }
  ],
  "scraped_at": "2024-01-15T10:30:00.000Z",
  "status": "success"
}
```

#### ğŸ›’ POST `/scrape/products`
Extrai produtos de pÃ¡ginas de e-commerce

**Request:**
```json
{
  "url": "https://shop.example.com/products"
}
```

**Response:**
```json
{
  "url": "https://shop.example.com/products",
  "products": [
    {
      "name": "Product Name",
      "price": "R$ 99,90",
      "image": "https://shop.example.com/product-image.jpg",
      "link": "https://shop.example.com/product/123"
    }
  ],
  "total_found": 15,
  "scraped_at": "2024-01-15T10:30:00.000Z",
  "status": "success"
}
```

## ğŸ§ª Testando a API

### Usando o script de teste incluÃ­do:

```bash
python test_api.py
```

### Usando curl:

```bash
# Health check
curl http://localhost:5000/health

# Scraping bÃ¡sico
curl -X POST http://localhost:5000/scrape \
  -H "Content-Type: application/json" \
  -d '{"url": "https://httpbin.org/html"}'

# Scraping de produtos
curl -X POST http://localhost:5000/scrape/products \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example-shop.com"}'
```

### Usando Python:

```python
import requests

# Scraping bÃ¡sico
response = requests.post('http://localhost:5000/scrape', 
                        json={'url': 'https://example.com'})
print(response.json())

# Scraping de produtos
response = requests.post('http://localhost:5000/scrape/products', 
                        json={'url': 'https://shop.example.com'})
print(response.json())
```

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

- `FLASK_ENV` - Ambiente da aplicaÃ§Ã£o (development/production)
- `PORT` - Porta da aplicaÃ§Ã£o (default: 5000)

### Headers Personalizados

A API usa headers otimizados para evitar bloqueios:
```python
'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
```

## ğŸš€ Deploy

### Heroku

```bash
# Instale o Heroku CLI e faÃ§a login
heroku create sua-api-webscraping

# Deploy
git push heroku main
```

### Railway/Render

1. Conecte seu repositÃ³rio GitHub
2. Configure as variÃ¡veis de ambiente
3. Deploy automÃ¡tico

## ğŸ¯ Casos de Uso

- **Monitoramento de PreÃ§os** - Acompanhe preÃ§os de produtos em e-commerce
- **AnÃ¡lise de ConcorrÃªncia** - Colete dados de sites concorrentes
- **AgregaÃ§Ã£o de ConteÃºdo** - Compile informaÃ§Ãµes de mÃºltiplas fontes
- **SEO Analysis** - Extraia metadados e estrutura de pÃ¡ginas
- **Lead Generation** - Colete informaÃ§Ãµes de contato de websites

## âš ï¸ LimitaÃ§Ãµes e ConsideraÃ§Ãµes

- **Rate Limiting** - Respeite os limites dos sites
- **robots.txt** - Verifique as polÃ­ticas de scraping
- **JavaScript** - Esta API nÃ£o executa JavaScript (use Selenium para SPAs)
- **Timeout** - Requests tÃªm timeout de 10 segundos
- **Legal** - Use apenas em sites onde vocÃª tem permissÃ£o

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ Estrutura do Projeto

```
webscraping-api/
â”œâ”€â”€ app.py              # AplicaÃ§Ã£o principal
â”œâ”€â”€ requirements.txt    # DependÃªncias
â”œâ”€â”€ Dockerfile         # ConfiguraÃ§Ã£o Docker
â”œâ”€â”€ test_api.py        # Scripts de teste
â”œâ”€â”€ README.md          # DocumentaÃ§Ã£o
â””â”€â”€ .gitignore         # Arquivos ignorados
```

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ‘¨â€ğŸ’» Autor

**Seu Nome**
- GitHub: [@seu-usuario](https://github.com/seu-usuario)
- LinkedIn: [Seu LinkedIn](https://linkedin.com/in/seu-perfil)
- Email: seu.email@example.com

## ğŸ“Š Roadmap

- [ ] AutenticaÃ§Ã£o JWT
- [ ] Rate limiting por IP
- [ ] Cache Redis
- [ ] Suporte a JavaScript (Selenium)
- [ ] Webhooks para notificaÃ§Ãµes
- [ ] Dashboard web para monitoramento

---

â­ Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela!

ğŸ“« Tem alguma dÃºvida? Abra uma [issue](https://github.com/seu-usuario/webscraping-api/issues)!